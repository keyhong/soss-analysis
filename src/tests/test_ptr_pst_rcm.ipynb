{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626af1f-6b63-4f5a-a132-17a941181dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5e58c-33b8-40ea-89a3-fe58a2daadd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c88d1e7-ac1f-41ca-a86a-5d9565906cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_soss_ptr_pst(today):\n",
    "    \n",
    "    from sqlalchemy import create_engine\n",
    "    from sqlalchemy.orm import Session\n",
    "    \n",
    "    # Create an engine to connect to the database\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_database}\")\n",
    "    \n",
    "    # 세션을 사용하여 데이터베이스 작업 수행\n",
    "    with Session(engine) as session:\n",
    "        try:\n",
    "            # 데이터 삭제\n",
    "            session.execute(f\"DELETE FROM SOSS.DM_PTR_PST WHERE stdr_de='{today}'\")\n",
    "\n",
    "            # 정상 수행시 commit\n",
    "            session.flush()\n",
    "            print('hi')\n",
    "            logging.info(f'순찰거점 {today} 날짜 삭제!{line_break}')\n",
    "        except:\n",
    "            # 에러 발생시 commit\n",
    "            logging.error(f\"SESSION NOT ACCESS\")\n",
    "            \n",
    "            # 예외가 발생한 경우 롤백\n",
    "            session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d14cb7f-e25c-4672-b14f-dbf4780d84f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:35: SESSION NOT ACCESS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# Create an engine to connect to the database\n",
    "engine = create_engine(f\"postgresql+psycopg2://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_database}\")\n",
    "\n",
    "# 세션을 사용하여 데이터베이스 작업 수행\n",
    "with Session(engine) as session:\n",
    "    try:\n",
    "        # 데이터 삭제\n",
    "        session.execute(f\"DELETE FROM SOSS.DM_PTR_PST WHERE stdr_de='{today}'\")\n",
    "\n",
    "        print('hi')\n",
    "        \n",
    "        # 정상 수행시 commit\n",
    "        session.flush()\n",
    "        \n",
    "        logging.info(f'순찰거점 {today} 날짜 삭제!{line_break}')\n",
    "    except:\n",
    "        # 에러 발생시 commit\n",
    "        logging.error(f\"SESSION NOT ACCESS\")\n",
    "        \n",
    "        # 예외가 발생한 경우 롤백\n",
    "        session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cca12-5a5e-4c9e-8788-e25cdeaf61f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d9f1b38-56d0-46d1-aa5c-f31882f6ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:01: SESSION NOT ACCESS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실행\n",
      "실행\n",
      "실행\n"
     ]
    }
   ],
   "source": [
    "# 세션을 사용하여 데이터베이스 작업 수행\n",
    "with Session(engine) as session:\n",
    "    try:\n",
    "        tables = (\n",
    "            'SOSS.DM_SAFE_IDEX_GRID',\n",
    "            'SOSS.DM_SAFE_IDEX_ADMD',\n",
    "            'SOSS.DM_SAFE_IDEX_SGG'\n",
    "        )\n",
    "\n",
    "        for table in tables:\n",
    "\n",
    "            # 데이터 삭제\n",
    "            session.execute(f\"DELETE FROM {table} WHERE stdr_de='{today}'\")\n",
    "            print('실행')\n",
    "\n",
    "        # 정상 수행시 commit\n",
    "        session.flush()\n",
    "        logging.info(f'안전지수 {today} 날짜 삭제!{line_break}')\n",
    "    except:\n",
    "        # 에러 발생시 commit\n",
    "        logging.error(f\"SESSION NOT ACCESS\")\n",
    "        \n",
    "        # 예외가 발생한 경우 롤백\n",
    "        session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee63e99-679e-4ea5-803f-e9ed9db4ba84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c072b72-bbb9-4cf3-8bbc-2161683a0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from typing import (\n",
    "    Type,\n",
    "    List,\n",
    "    Tuple,\n",
    ")\n",
    "import logging\n",
    "from decimal import Decimal\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from pyspark.sql.utils import ParseException\n",
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from log_object import LogObject\n",
    "\n",
    "sys.path.insert(0, '/home/icitydatahub/soss/spark_session')\n",
    "from db_connector import SparkClass\n",
    "\n",
    "sys.path.insert(0, '/home/icitydatahub/soss/queries')\n",
    "from ptr_pst_rcm_query import QueryCollection\n",
    "\n",
    "sys.path.insert(0, '/home/icitydatahub/soss/utils')\n",
    "from config_parser import *\n",
    "\n",
    "# 인천시 네모 그리드 x좌표의 왼쪽 최소값\n",
    "min_x_crd = 746758.991784\n",
    "\n",
    "# 인천시 네모 그리드 y좌표의 위쪽 최대값\n",
    "min_y_crd = 1883404.14739\n",
    "\n",
    "MONTH_PERIOD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ed63db3-5aea-4b23-9f4c-7ca9468acd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:18:11: Main-Process : start\n",
      "00:18:11: -- spark load --\n",
      "\n",
      "00:18:11: Jung-gu Start --\n"
     ]
    }
   ],
   "source": [
    "# new line str\n",
    "new_line = '\\n'\n",
    "\n",
    "# logging setting\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n",
    "logging.info(\"Main-Process : start\")\n",
    "start = time.time()\n",
    "\n",
    "logging.info(f\"-- spark load --{new_line}\")\n",
    "\n",
    "# .py 실행 파라미터로 첫번째 인자에 실행현재(YYYYMMDD) 날짜가 들어옴\n",
    "today = str(sys.argv[1])\n",
    "today = '20230628'\n",
    "assert len(today) == 8, \"입력일자는 YYYYMMDD 형식 입니다\"\n",
    "\n",
    "# today를 datetime 타입으로 변환하여 저장하는 변수\n",
    "today_dt : Type[datetime] = datetime.strptime(today, '%Y%m%d')\n",
    "\n",
    "# 인천 구 딕셔너리 (구 이름 : 구 코드)\n",
    "gu_dict = {\n",
    "    'Jung-gu': 28110,\n",
    "    'Dong-gu': 28140,\n",
    "    'Michuhol-gu': 28177,\n",
    "    'Yeonsu-gu': 28185,\n",
    "    'Namdong-gu': 28200,\n",
    "    'Bupyeong-gu': 28237,\n",
    "    'Gyeyang-gu': 28245,\n",
    "    'Seo-gu': 28260,\n",
    "    'Ganghwa-gun': 28710,\n",
    "    'Ongjin-gun': 28720\n",
    "}\n",
    "    \n",
    "gu_nm = 'Jung-gu'\n",
    "gu_cd = 28110\n",
    "\n",
    "logging.info(f'{gu_nm} Start --')\n",
    "\n",
    "# safe_idex_query 인스턴스 생성\n",
    "query_obj = QueryCollection(today, gu_cd)\n",
    "\n",
    "record_cnt = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d1207-7837-4cb7-a83d-7f34762d6a4b",
   "metadata": {},
   "source": [
    "# delete_soss_ptr_pst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4757d814-4185-49ea-b310-302fca763aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_soss_ptr_pst(today):\n",
    "    \n",
    "    from sqlalchemy import create_engine\n",
    "    from sqlalchemy.orm import Session\n",
    "    \n",
    "    # Create an engine to connect to the database\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_database}\")\n",
    "    \n",
    "    # 세션을 사용하여 데이터베이스 작업 수행\n",
    "    with Session(engine) as session:\n",
    "        try:\n",
    "            # 데이터 삭제\n",
    "            session.execute(f\"DELETE FROM SOSS.DM_PTR_PST WHERE stdr_de='{today}'\")\n",
    "\n",
    "            # 정상 수행시 commit\n",
    "            session.commit()\n",
    "            logging.info(f'순찰거점 {today} 날짜 삭제!{line_break}')\n",
    "            \n",
    "        except:\n",
    "            # 에러 발생시 commit\n",
    "            logging.error(f\"SESSION NOT ACCESS\")\n",
    "            \n",
    "            # 예외가 발생한 경우 롤백\n",
    "            session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78166e9b-e337-42a0-8745-97f33af07ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:59:00: SESSION NOT ACCESS\n"
     ]
    }
   ],
   "source": [
    "# 기존 날짜에 데이터가 있다면 삭제\n",
    "delete_soss_ptr_pst(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb08d9-fd1d-48fd-aa16-1c96ab1bcec9",
   "metadata": {},
   "source": [
    "# create_data_mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7466e-52f5-44eb-a345-68333238c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_mart() -> 'pandas.DataFrame':\n",
    "    \"\"\"안전도 데이터에 그리드 좌표, 지구대 데이터를 결합하여 통합 데이터마트 구축하는 함수\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merge_df : pandas.DataFrame\n",
    "       input 데이터 프레임에 인천시그리드 좌표 정보와 지구대 정보를 결합한 데이터 프레임\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    safe_df에 인천 그리드 좌표 정보 테이블과 행정동 지구대 매핑 테이블을 left_join으로 순차적으로 결합시켜 통합 데이터 마트를 생성\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 안전지수 그리드 데이터 로딩\n",
    "    try:\n",
    "        safe_df = query_obj.get_dm_safe_idex_grid_sql()\n",
    "        if not safe_df.take(1):\n",
    "            logging.error(\"Fucntion : get_dm_safe_idex_grid_sql() 쿼리로 가져오는 데이터가 없습니다\")\n",
    "    except ParseException as e:\n",
    "        logging.error(f'ParseException : {e}')\n",
    "    except Py4JJavaError as e:\n",
    "        logging.error(f'Py4JJavaError : {e}')\n",
    "    else:\n",
    "        safe_df = safe_df.toPandas()\n",
    "        safe_df['ptr_tmzn_cd'] = safe_df['stdr_tm'] // 4\n",
    "        safe_df = safe_df.groupby(by=['grid_id', 'ptr_tmzn_cd'], as_index=False)['safe_idex'].mean()\n",
    "\n",
    "    # 2. 인천시 그리드 좌표 데이터 로딩\n",
    "    try:\n",
    "        pcell_info = query_obj.get_ic_pcel_stdr_info_sql()\n",
    "        if not pcell_info.take(1):\n",
    "            logging.error(\"Fucntion : get_ic_pcel_stdr_info_sql() 쿼리로 가져오는 데이터가 없습니다\")\n",
    "    except ParseException as e:\n",
    "        logging.error(f'ParseException : {e}')\n",
    "    except Py4JJavaError as e:\n",
    "        logging.error(f'Py4JJavaError : {e}')\n",
    "    else:\n",
    "        pcell_info = pcell_info.toPandas()\n",
    "\n",
    "        # 구 안전도 데이터와 그리드 좌표(pcell_info) 결합하여 데이터프레임 생성\n",
    "        merge_df = safe_df.merge(pcell_info, how='left', on='grid_id')\n",
    "\n",
    "    # 3. 같은 일자기준 최근 유동인구 정보가 있는 그리드만 추출\n",
    "    try:\n",
    "        for year in range(0, 5):\n",
    "            # 일자 설정\n",
    "            start_date = (today_dt - relativedelta(years=year, months=MONTH_PERIOD)).strftime('%Y%m%d')\n",
    "            end_date = (today_dt - relativedelta(years=year, days=1)).strftime('%Y%m%d')\n",
    "\n",
    "            # (MONTH_PERIOD 개월 전 ~ 어제) 사이 유동인구 값이 있는 그리드 ID만 추출\n",
    "            unique_grid = query_obj.get_distinct_grid_id_sql(start_date, end_date)\n",
    "\n",
    "            if unique_grid.take(1):\n",
    "                break\n",
    "    except ParseException as e:\n",
    "        logging.error(f'ParseException : {e}')\n",
    "    except Py4JJavaError as e:\n",
    "        logging.error(f'Py4JJavaError : {e}')\n",
    "    else:\n",
    "        unique_grid = unique_grid.toPandas()\n",
    "        unique_grid = unique_grid['grid_id']\n",
    "        merge_df = merge_df[merge_df['grid_id'].isin(unique_grid)]\n",
    "        \n",
    "    # 4. 행정동지구대매핑 데이터 로딩\n",
    "    try:\n",
    "        admd_plbx_mapn_df: 'pyspark.sql.DataFrame' = query_obj.get_admd_plbx_mapn_sql()\n",
    "        if not admd_plbx_mapn_df.take(1):\n",
    "            logging.error(\"Fucntion : get_admd_plbx_mapn_sql() 쿼리로 가져오는 데이터가 없습니다\")\n",
    "    except ParseException as e:\n",
    "        logging.error(f'ParseException : {e}')\n",
    "    except Py4JJavaError as e:\n",
    "        logging.error(f'Py4JJavaError : {e}')\n",
    "    else:\n",
    "        admd_plbx_mapn_df = admd_plbx_mapn_df.toPandas()\n",
    "        admd_plbx_mapn_df = admd_plbx_mapn_df.astype({'ptr_vhcl_co': 'Int16'})\n",
    "\n",
    "        # 행정동지구대메핑 테이블 결합\n",
    "        merge_df = merge_df.merge(admd_plbx_mapn_df, how='left', on='admd_cd')\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4e335-70ec-484a-a5ff-c2e0a1373455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. 인천시 안전지수 데이터, 인천PCELL 기준정보, 행정동지구대매핑 데이터를 결합하여 Data Mart 생성\n",
    "merge_df = create_data_mart()\n",
    "logging.info('-- create_data_mart() 종료 --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29354cd-8f2d-4f64-8c47-581f6d1a6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf40af4-3697-4d38-b82f-308e14486f44",
   "metadata": {},
   "source": [
    "# make_safe_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ee65c-2021-48d8-b14d-254acf1ed183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_safe_grade(merge_df: 'pandas.DataFrame') -> 'pandas.DataFrame':\n",
    "    \"\"\"안전도 값(0~100)을 순찰거점분석용 안전등급 부여하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    merge_df : pandas.DataFrame\n",
    "       데이터 결합이 완료된 통합 데이터 프레임\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merge_df : pandas.DataFrame\n",
    "       merge_df에 safe_grade(안전등급)이 컬럼이 추가된 데이터 프레임\n",
    "    \"\"\"\n",
    "\n",
    "    # 안전도 등급(위험|주의|안전) 구분하기 위한 로직 설정\n",
    "    merge_df['plbx_tmzn_ranking'] = merge_df.groupby(['plbx_nm','ptr_tmzn_cd'])['safe_idex'].rank(method='min')\n",
    "\n",
    "    # 지구대별-순찰시간대코드별 그리드 개수\n",
    "    grouped_df = merge_df.groupby(['plbx_nm', 'ptr_tmzn_cd'], as_index=False)['grid_id'].count()\n",
    "    grouped_df.rename(columns={'grid_id': 'plbx_tmzn_grid_cnt'}, inplace=True)\n",
    "\n",
    "    # 지구대별-순찰시간대코드별 그리드 데이터 병합\n",
    "    merge_df = merge_df.merge(grouped_df, how='left', on=['plbx_nm', 'ptr_tmzn_cd'])\n",
    "\n",
    "    ''' 안전등급 분류 '''\n",
    "\n",
    "    # 주의 : 지구대별-순찰시간대코드별 그리드 개수의 하위 10%\n",
    "    caution_condition = (merge_df['plbx_tmzn_ranking'] < (0.1 * merge_df['plbx_tmzn_grid_cnt']))\n",
    "\n",
    "    # 위험 : (지구대별-순찰시간대코드   별 그리드 개수의 하위 10%) & (안전도 60 미만)\n",
    "    danger_condition = caution_condition & (merge_df['safe_idex'] < 60)\n",
    "\n",
    "    merge_df['safe_grade'] = np.where(danger_condition, \"위험\", np.where(caution_condition, \"주의\", \"안전\"))\n",
    "\n",
    "    # 불필요한 컬럼(plbx_tmzn_grid_cnt) 제거\n",
    "    merge_df.drop(['plbx_tmzn_ranking', 'plbx_tmzn_grid_cnt'] , axis=1, inplace=True)\n",
    "\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb34bb-ad5e-4cb5-95fb-df880098c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. 안전지수의 파생변수 안전등급 생성\n",
    "merge_df = make_safe_grade(merge_df)\n",
    "logging.info('-- make_safe_grade() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef016cca-0461-4551-b63f-955a38b0120b",
   "metadata": {},
   "source": [
    "# append_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65c957-0454-4b4b-82ec-50f4fac6308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_weight(dataFrame: 'pandas.DataFrame', weight: int=9) -> 'pandas.DataFrame':\n",
    "    \"\"\"가중치 비율 계산에 따라 위험(red)지역은 10배 데이터복제(가중치부여) 하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataFrame : pandas.DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # SAFE_GRADE가 위험인 데이터프레임과 위험이 아닌 데이터프레임 분리\n",
    "    danger_df = dataFrame[dataFrame['safe_grade'] == \"위험\"]\n",
    "    not_danger_df = dataFrame[dataFrame['safe_grade'] != \"위험\"]\n",
    "\n",
    "    # SAFE_GRADE가 위험인 데이터프레임 가중치만큼 복제\n",
    "    danger_df = pd.concat([danger_df] * weight, ignore_index=True)\n",
    "\n",
    "    # 기존 데이터프레임에 복제 데이터프레임 행 결합\n",
    "    result_df = pd.concat([danger_df, not_danger_df], ignore_index=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391bb0b-a15a-4f87-a624-5376be405796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. 가중치 부여 함수 실행 => 위험, 주의 그리드만 별도 추출 & 위험그리드 가중치 부여\n",
    "merge_df = append_weight(merge_df, weight=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e1d14-9799-4a49-a6ba-2abbef4600e0",
   "metadata": {},
   "source": [
    "# make_log_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a76cc-44ec-44f4-97ef-d589f6503995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_object():\n",
    "    \n",
    "    # 순찰거점을 기록할 로그 데이터\n",
    "    log_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            'plbx_nm', # 지구대명\n",
    "            'ptr_tmzn_cd', # 순찰시간대코드\n",
    "            'gu_cd', # 구코드\n",
    "            'admd_cd', # 행정동코드\n",
    "            'lo', # 경도\n",
    "            'la', # 위도\n",
    "            'grid_id', # 그리드ID\n",
    "            'avrg_safe_idex', # 평균안전지수\n",
    "            'ptr_vhcl_co', # 순찰차량수\n",
    "            'bst_clsr_co', # 최적군집수\n",
    "            'ptr_pst_cd' # 순찰거점코드\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    log_df = log_df.astype(\n",
    "        {\n",
    "            'plbx_nm': str,\n",
    "            'ptr_tmzn_cd': 'Int32',\n",
    "            'gu_cd': str,\n",
    "            'admd_cd': str,\n",
    "            'lo': np.float64,\n",
    "            'la': np.float64,\n",
    "            'grid_id': str,\n",
    "            'avrg_safe_idex': np.float64,\n",
    "            'ptr_vhcl_co': 'Int16',\n",
    "            'bst_clsr_co': 'Int16',\n",
    "            'ptr_pst_cd': str\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # log_instance 객체 생성\n",
    "    log_instance = LogObject()\n",
    "    log_instance.gu_cd = str(gu_cd)\n",
    "    \n",
    "    return log_df, log_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db8b50-db80-442f-b0df-d09e9bdabbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. log 저장 객체 생성\n",
    "log_df, log_instance = make_log_object()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1720d-8eb2-4e5e-b1c6-87c7c2db0ea7",
   "metadata": {},
   "source": [
    "# kmeans_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0082c-7dd4-49b5-87af-c915f287ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_modeling(merge_df: 'pandas.DataFrame') -> 'pandas.DataFrame':\n",
    "    \"\"\"지구대별, 일자별, 시간대별 군집분석 실시 후 시각화파일 & 결과기록(로그)파일을 저장하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    merge_df : pandas.DataFrame\n",
    "       그리드 좌표, 지구대 정보 결합 후 안전등급 컬럼이 추가된 데이터 프레임\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    log_df : pandas.DataFrame\n",
    "       모든 지구대, 일자, 시간대별 순찰거점 기록이 완료된 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    global log_instance, all_grid_array\n",
    "    \n",
    "    # 지구대명 반복문 실행\n",
    "    for plbx_nm in np.unique(merge_df['plbx_nm']):\n",
    "\n",
    "        # 지구대 명별(plbx_nm) 쿼리\n",
    "        plbx_df = merge_df[merge_df['plbx_nm'] == plbx_nm]\n",
    "\n",
    "        # 안전 그리드가 포함되어 있는 데이터 프레임 변수 생성 (이상 순찰거점 점검을 위해 생성)\n",
    "        all_grid_array = plbx_df['mtr_no'].copy()\n",
    "        \n",
    "        log_instance.plbx_nm = plbx_nm\n",
    "        log_instance.admd_cd = plbx_df['admd_cd'].values[0]\n",
    "\n",
    "        # 순찰시간대코드별 반복문 실행\n",
    "        for ptr_tmzn_cd in np.unique(merge_df['ptr_tmzn_cd']):\n",
    "\n",
    "            logging.info(f'-- {plbx_nm}-{ptr_tmzn_cd} 시작 --')\n",
    "\n",
    "            # 순찰 시간대 코드별(ptr_tmzn_cd) 쿼리\n",
    "            plbx_tmzn_df = plbx_df[plbx_df['ptr_tmzn_cd'] == ptr_tmzn_cd]\n",
    "\n",
    "            # 값이 없으면 contiunue\n",
    "            if plbx_tmzn_df.empty:\n",
    "                continue\n",
    "\n",
    "            log_instance.ptr_tmzn_cd = ptr_tmzn_cd\n",
    "\n",
    "            # 지구대별 소유 순찰차량 수\n",
    "            ptr_vhcl_co = plbx_tmzn_df['ptr_vhcl_co'].values[0]\n",
    "            log_instance.ptr_vhcl_co = ptr_vhcl_co\n",
    "\n",
    "            # K-means에 사용할 군집 X좌표, Y좌표\n",
    "            x_data = plbx_tmzn_df[['cnt_x_crd', 'cnt_y_crd']]\n",
    "\n",
    "            # 최적 군집 수 탐색하기\n",
    "            for cluster_cnt in range(2, 6):\n",
    "\n",
    "                # K-means parameter(군집을 나눌 개수) : 순찰차 수로 설정\n",
    "                kmeans = KMeans(n_clusters=cluster_cnt, random_state=2023).fit(x_data)\n",
    "\n",
    "                if cluster_cnt == 2:\n",
    "\n",
    "                    # 최적 군집 수 초기화\n",
    "                    bst_clsr_co = cluster_cnt\n",
    "\n",
    "                    # 최적의 군집 개수 탐색을 위한 K-means 모델링 & 실루엣 계수 값 비교\n",
    "                    max_silhouette_score = silhouette_score(x_data, kmeans.labels_)\n",
    "                    plbx_tmzn_df['cluster_idx'] = kmeans.labels_\n",
    "\n",
    "                   # 순찰거점 좌표 반환\n",
    "                    centroids = kmeans.cluster_centers_\n",
    "                \n",
    "                else:\n",
    "                    compare_silhouette_score = silhouette_score(x_data, kmeans.labels_)\n",
    "                    \n",
    "                    # 기존 최대 실루엣 계수값과 새로운 실루엣 계수 값을 비교\n",
    "                    if max_silhouette_score < compare_silhouette_score:\n",
    "                        \n",
    "                        # 최적 군집 수 변경\n",
    "                        bst_clsr_co = cluster_cnt\n",
    "                        \n",
    "                        # 최대 실루엣 계수 변경\n",
    "                        max_silhouette_score = compare_silhouette_score\n",
    "                        plbx_tmzn_df['cluster_idx'] = kmeans.labels_\n",
    "                        \n",
    "                        # 순찰거점 좌표 반환\n",
    "                        centroids = kmeans.cluster_centers_\n",
    "\n",
    "            # 최적군집, 순찰차량 로그 출력\n",
    "            logging.info(f'{plbx_nm} {ptr_tmzn_cd} 순찰시간대 :  최적군집 수 {bst_clsr_co} | 순찰차량 수 {ptr_vhcl_co}')\n",
    "\n",
    "            # 최적 군집 수 기록\n",
    "            log_instance.bst_clsr_co = bst_clsr_co\n",
    "\n",
    "            # 클러스터 개수를 기반으로 다른 두 가지 군집함수 케이스 실행\n",
    "            if bst_clsr_co == ptr_vhcl_co:\n",
    "                log_instance.ptr_pst_cd = '4'\n",
    "                patrol_fit(plbx_tmzn_df, centroids)\n",
    "\n",
    "            elif bst_clsr_co > ptr_vhcl_co:\n",
    "                log_instance.ptr_pst_cd = '1'\n",
    "                cluster_primary(plbx_tmzn_df, centroids)\n",
    "            else:\n",
    "                log_instance.ptr_pst_cd = '3'\n",
    "                cluster_over(plbx_tmzn_df, centroids)\n",
    "\n",
    "def patrol_fit(plbx_tmzn_df: 'pandas.DataFrame', centroids: Tuple[float]) -> 'pandas.DataFrame':\n",
    "    \"\"\"PF (Patrol Fit, 최적군집 수와 순찰차 수가 일치하여 그대로 군집 중점을 도출한 거점)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plbx_tmzn_df : pandas.DataFrame\n",
    "       지구대명, 기준일자, 순찰시간대코드 쿼리 후 위험 가중치가 반영된 데이터 프레임\n",
    "\n",
    "    centroids : Tuple[float]\n",
    "\n",
    "    log_df: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    global log_df, log_instance\n",
    "    \n",
    "    # 순찰차 갯수 만큼 해당 지역을 군집\n",
    "    for idx, centroid in enumerate(centroids):\n",
    "\n",
    "        # cluster별 쿼리 (순찰거점은 각 cluster의 중점)\n",
    "        cluster_df = plbx_tmzn_df[plbx_tmzn_df['cluster_idx'] == idx]\n",
    "\n",
    "        # 군집 평균 안전도 기재\n",
    "        log_instance.avrg_safe_idex= round(cluster_df['safe_idex'].mean(), 3)\n",
    "\n",
    "        # 정상 군집 거점 확인\n",
    "        check_right_position(centroid[0], centroid[1], cluster_df)\n",
    "\n",
    "        # 최종 순찰거점의 정보를 기록\n",
    "        log_df = pd.concat([log_df, log_instance.get_info_dataframe()], ignore_index=True)\n",
    "\n",
    "\n",
    "def cluster_primary(plbx_tmzn_df: 'pandas.DataFrame', centroids: Tuple[float]) -> 'pandas.DataFrame':\n",
    "    \"\"\"CP (Cluster Primary, 최적군집 수가 보유한 순찰차 수 보다 많은 경우 우선적으로 중요 거점을 선택하여 거점 도출)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plbx_tmzn_df : pandas.DataFrame\n",
    "       지구대명, 기준일자, 순찰시간대코드 쿼리 후 위험 가중치가 반영된 데이터 프레임\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 군집별 평균안전도 비교를 통해 우선 거점 분류 \n",
    "    \n",
    "    global log_df, log_instance\n",
    "\n",
    "    # 오름차순으로 평균안전도 순서를 매김\n",
    "    cluster_ranking = plbx_tmzn_df.groupby('cluster_idx', as_index=False)['safe_idex'].mean()\n",
    "    cluster_ranking['ranking'] = cluster_ranking['safe_idex'].rank(method='min')\n",
    "\n",
    "    # 내림차순 순위를 매겼을 때, 순찰차 수 이하의 cluster는 주요 거점 (순위 숫자가 낮을 수록, 평균 안전도 낮음 => 우선 예방)\n",
    "    primary_idxs = cluster_ranking[cluster_ranking['ranking'] <= log_instance.ptr_vhcl_co]['cluster_idx'].values\n",
    "\n",
    "    for primary_idx in primary_idxs:\n",
    "\n",
    "        # cluster별 쿼리 (순찰거점은 각 cluster의 중점)\n",
    "        cluster_df = plbx_tmzn_df[plbx_tmzn_df['cluster_idx'] == primary_idx]\n",
    "\n",
    "        # 군집 평균 안전도 기재\n",
    "        log_instance.avrg_safe_idex = round(cluster_df['safe_idex'].mean(), 3)\n",
    "\n",
    "        # 정상 군집 거점 확인\n",
    "        check_right_position(centroids[primary_idx][0], centroids[primary_idx][1], cluster_df)\n",
    "\n",
    "        # 최종 순찰거점의 정보를 기록\n",
    "        log_df = pd.concat([log_df, log_instance.get_info_dataframe()], ignore_index=True)\n",
    "\n",
    "\n",
    "def cluster_over(plbx_tmzn_df: 'pandas.DataFrame', centroids: Tuple[float]) -> 'pandas.DataFrame':\n",
    "    \"\"\"CO (Cluster Over, 보유한 순찰차 수가 최적군집 수 보다 많은 경우 범위가 가장 넓은 군집에 대하여 한번 더 군집분석을 하여 순찰범위를 줄여 도출한 거점 도출)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plbx_tmzn_df : pandas.DataFrame\n",
    "       지구대명, 기준일자, 순찰시간대코드 쿼리 후 위험 가중치가 반영된 데이터 프레임\n",
    "\n",
    "    log_instance : LogObject\n",
    "       'CO' (Cluster Over) 순찰거점 정보를 기록할 인스턴스\n",
    "    \"\"\"\n",
    "    \n",
    "    global log_df, log_instance\n",
    "\n",
    "    ''' 1. 군집별 그리드 개수 비교를 통해 추가 군집 모델링할 거점 분류 '''\n",
    "    spare_car = log_instance.ptr_vhcl_co - log_instance.bst_clsr_co\n",
    "\n",
    "    # 내림차순으로 그리드 개수가 많은 클러스터의 순서 번호를 매김 (그리드 개수가 많을수록, 랭킹이 높음)\n",
    "    cluster_ranking = plbx_tmzn_df.groupby('cluster_idx', as_index=False)['grid_id'].count()\n",
    "    cluster_ranking['ranking'] = cluster_ranking['grid_id'].rank(ascending=False, method='min')\n",
    "\n",
    "    no_additional_cluster_idxs = cluster_ranking[cluster_ranking['ranking'] > spare_car]['cluster_idx'].values\n",
    "    additional_cluster_idx = cluster_ranking[cluster_ranking['ranking'] <= spare_car]['cluster_idx'].values\n",
    "\n",
    "    ''' 2. 군집분석을 추가로 하지 않는 군집 로그 기록 '''\n",
    "    for no_additional_cluster_idx in no_additional_cluster_idxs:\n",
    "\n",
    "        # cluster별 쿼리 (순찰거점은 각 cluster의 중점)\n",
    "        cluster_df = plbx_tmzn_df[plbx_tmzn_df['cluster_idx'] == no_additional_cluster_idx]\n",
    "\n",
    "        # 군집 평균 안전도 기재\n",
    "        log_instance.avrg_safe_idex = round(cluster_df['safe_idex'].mean(), 3)\n",
    "\n",
    "        # 정상 군집 거점 확인\n",
    "        check_right_position(centroids[no_additional_cluster_idx][0], centroids[no_additional_cluster_idx][1], cluster_df)\n",
    "\n",
    "        # 최종 순찰거점의 정보를 기록\n",
    "        log_df = pd.concat([log_df, log_instance.get_info_dataframe()], ignore_index=True)\n",
    "\n",
    "\n",
    "    ''' 3. 추가 군집분석 로그 기록 '''\n",
    "    # 군집분석을 추가로 하는 군집 데이터 추출\n",
    "    additional_cluster_df = plbx_tmzn_df[plbx_tmzn_df['cluster_idx'].isin(additional_cluster_idx)]\n",
    "\n",
    "    # K-means에 사용할 군집 X좌표, Y좌표\n",
    "    x_data = additional_cluster_df[['cnt_x_crd', 'cnt_y_crd']]\n",
    "\n",
    "    # spare_car + len(additional_cluster_idx) : (남는 순찰차 대수 + 추가 군집할 idx개수)개로 해당 클러스터에 군집 시행\n",
    "    kmeans = KMeans(n_clusters=spare_car+len(additional_cluster_idx), random_state=int(today[0:4])).fit(x_data)\n",
    "\n",
    "    # 데이터에 군집 클러스터 부여\n",
    "    additional_cluster_df['cluster_idx'] = kmeans.labels_\n",
    "\n",
    "    # 순찰거점 좌표 반환\n",
    "    additional_centroids = kmeans.cluster_centers_\n",
    "\n",
    "    for idx, centroid in enumerate(additional_centroids):\n",
    "\n",
    "        # cluster별 쿼리 (순찰거점은 각 cluster의 중점)\n",
    "        cluster_df = additional_cluster_df[additional_cluster_df['cluster_idx'] == idx]\n",
    "\n",
    "        # 군집 평균 안전도 기재\n",
    "        log_instance.avrg_safe_idex = round(cluster_df['safe_idex'].mean(), 3)\n",
    "\n",
    "        # 정상 군집 거점 확인\n",
    "        check_right_position(centroid[0], centroid[1], cluster_df)\n",
    "\n",
    "        # 최종 순찰거점의 정보를 기록\n",
    "        log_df = pd.concat([log_df, log_instance.get_info_dataframe()], ignore_index=True)\n",
    "\n",
    "def check_right_position(x_crd: float, y_crd: float, cluster_df: 'pandas.DataFrame'):\n",
    "    \"\"\"해당 거점이 이상거점인지 확인 후 거점이동하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_crd : float\n",
    "       확인하려는 순찰거점의 X좌표\n",
    "\n",
    "    y_crd : float\n",
    "       확인하려는 순찰거점의 Y좌표\n",
    "\n",
    "    cluster_df : pandas.DataFrame\n",
    "       K-means 모델링의 결과로 들어간 input 데이터프레임(해당 지역에서 위험으로 판단된 데이터, 지구대별 클러스터)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    log_instance : LogObject\n",
    "       log를 기록할 정보를 담은 instance\n",
    "    \"\"\"\n",
    "    \n",
    "    global log_instance\n",
    "\n",
    "    # 순찰거점좌표에 grid_id 부여하기\n",
    "    x_id = (Decimal(str(x_crd)) - Decimal(str(min_x_crd))) // Decimal('50')\n",
    "    y_id = (Decimal(str(y_crd)) - Decimal(str(min_y_crd))) // Decimal('50')\n",
    "\n",
    "    position = ','.join([str(x_id), str(y_id)])\n",
    "\n",
    "    # 순찰거점지역의 mtr_no가 input data의 grid_id에 있는지 조회 (정상 조건)\n",
    "    if sum(np.isin(element=all_grid_array, test_elements=position)) > 0:\n",
    "\n",
    "        # 순찰거점 이상징후가 없다면 그대로 원래의 순찰거점 정보를 반환\n",
    "        grid_id = cluster_df[cluster_df['mtr_no'] == position]['grid_id'].values[0]\n",
    "        lo = str(x_crd)\n",
    "        la = str(y_crd)\n",
    "    else:\n",
    "        logging.info('이상 거점 발견 : 조치 실행')\n",
    "\n",
    "        # 이상 거점과 동일 지구대에서 위험과 주의로 판단된 모든 그리드에 대해 최적 거리 계산\n",
    "        x_ids = cluster_df['mtr_no'].str.split(pat=',', expand=True).astype(int)[0]\n",
    "        y_ids = cluster_df['mtr_no'].str.split(pat=',', expand=True).astype(int)[1]\n",
    "        cluster_df['dist'] = np.sqrt((x_id - x_ids) ** 2) + ((y_id - y_ids) ** 2)\n",
    "\n",
    "        # 최적거리가 가장 짧은 데이터 추출\n",
    "        shortest_grid_df = cluster_df[cluster_df['dist'] == cluster_df['dist'].min()]\n",
    "\n",
    "        # 이상 순찰거점의 좌표를 위에서 추출된 데이터의 좌표로 이동\n",
    "        grid_id = shortest_grid_df['grid_id'].values[0]\n",
    "        lo = shortest_grid_df['cnt_x_crd'].values[0]\n",
    "        la = shortest_grid_df['cnt_y_crd'].values[0]\n",
    "\n",
    "    # 최종적으로 LogObject 인스턴스에 정보를 기입\n",
    "    log_instance.lo = float(lo)\n",
    "    log_instance.la = float(la)\n",
    "    log_instance.grid_id = grid_id\n",
    "\n",
    "    \n",
    "def transform_utmk_to_w84(df: 'pandas.DataFrame') -> 'pandas.Series':\n",
    "    \"\"\"좌표 변환 코드 : 좌표계를 WGS84(epsg:4326)으로 변환하는 코드\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 위도와 경도 컬럼나 있는 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    inProj = Proj(init='epsg:5179')\n",
    "    outProj = Proj(init='epsg:4326')\n",
    "\n",
    "    return pd.Series(transform(inProj, outProj, df[df.index[0]], df[df.index[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf0628-6424-48db-ac47-4e9971fe9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_modeling(merge_df)\n",
    "logging.info('-- kmeans_modeling() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c6e13f-e48c-4c3a-96b3-8e662f90dbf7",
   "metadata": {},
   "source": [
    "# 05. 순찰거점 좌표 형식 변환(UTMK -> WGS84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bc799-df19-48b8-be79-74bee8e5e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62eb1a-b7b8-49c1-90e3-d825d69fc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.la[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7ec90-3b78-4346-a30f-31d71ab50010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a0266-c915-4781-8910-7505c599a88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8d63e-bd5e-4ca5-8f39-aee8de469a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make geometry grid center point\n",
    "log_df['geometry'] = log_df.apply(lambda row: Point(row['lo'], row['la']), axis=1)\n",
    "\n",
    "# transform grid center point to EPSG:4326 (from EPSG:5179 to EPSG:4326)\n",
    "log_df = gpd.GeoDataFrame(log_df, geometry='geometry', crs=\"EPSG:5179\")\n",
    "log_df.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# store EPSG:4326 location\n",
    "log_df['new_lo'] = log_df['geometry'].astype(str).str[7:-1].str.split(' ').str[0]\n",
    "log_df['new_la'] = log_df['geometry'].astype(str).str[7:-1].str.split(' ').str[1]\n",
    "\n",
    "# drop geometry\n",
    "log_df.drop('geometry', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c413d3-c839-42a2-9c49-1456ae1f5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.la2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58179a67-6f0e-4818-84fa-a2c38f5f8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.new_la[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398d1c4-d532-43d6-9882-3b48f0fb8f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cf222-97ac-46df-80ef-37b5c988262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df[['lo2', 'la2']] = log_df[['lo', 'la']].apply(transform_utmk_to_w84, axis=1)\n",
    "logging.info('-- transform_utmk_to_w84() 종료 --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218d1e7-0c6c-427a-91ce-661335e9a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_spot_near_policebox(log_df: 'pandas.DataFrame', boundary: int=500) -> 'pandas.DataFrame':\n",
    "    \"\"\"지구대 반경 500 미터 내 순찰거점 제거 코드\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 위도와 경도 컬럼나 있는 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        plbx_info = query_obj.get_plbx_info_sql()\n",
    "        if not plbx_info.take(1):\n",
    "            logging.error(\"Fucntion : get_plbx_info_sql() 쿼리로 가져오는 데이터가 없습니다\")\n",
    "    except ParseException as e:\n",
    "        logging.error(f'ParseException : {e}')\n",
    "    except Py4JJavaError as e:\n",
    "        logging.error(f'Py4JJavaError : {e}')\n",
    "    else:\n",
    "        plbx_info = plbx_info.toPandas()\n",
    "\n",
    "    tmp_df = log_df.merge(plbx_info, how='left', on='plbx_nm')\n",
    "\n",
    "    # 거리 계산\n",
    "    from haversine import haversine\n",
    "    tmp_df['dist'] = tmp_df.apply(lambda loc: haversine((loc['la'], loc['lo']), (loc['plbx_la'], loc['plbx_lo']), unit='m'), axis=1)\n",
    "\n",
    "    log_df.drop(tmp_df[tmp_df.dist <= 500].index, inplace=True)\n",
    "\n",
    "    return log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b0b7f-7a1a-4c75-9928-3d594b643636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. 지구대 반경 500미터 내 순찰거점 제거 함수\n",
    "log_df = delete_spot_near_policebox(log_df)\n",
    "logging.info('-- delete_spot_near_policebox() 종료 --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ff2fd-e763-41b7-b71c-2fbee04139df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04b798-30db-4add-b46f-5210a3c0baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자 추가\n",
    "log_df['stdr_de'] = today\n",
    "\n",
    "# pst_sn 코드 추가\n",
    "log_df['pst_sn'] = log_df.reset_index().index + 1 + record_cnt\n",
    "\n",
    "record_cnt = log_df['pst_sn'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725f367-564b-4eda-a955-7cbd5d4eafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pst_sn 코드 추가\n",
    "log_df['pst_sn'] = log_df.reset_index().index + 1 + record_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc7cc3-5d54-4756-ac97-29c78e91112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. 데이터 parquet로 적재하기\n",
    "spark_log = SparkClass.spark.createDataFrame(log_df)\n",
    "query_obj.insert_ptr_pst_sql(spark_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58720657-8946-4bb9-9e30-b6dc14927302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
