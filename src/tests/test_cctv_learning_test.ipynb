{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e208721-ab5f-492d-b069-52895e39ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e6550a-b238-489b-b46e-a39b2374f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/08 15:42:05 WARN Utils: Your hostname, safe-service resolves to a loopback address: 127.0.0.1; using 172.31.35.243 instead (on interface eth0)\n",
      "23/06/08 15:42:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/06/08 15:42:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/08 15:42:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Packages Loading\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ec2-user/workspace/01.Incheon/02_cctv_optmz')\n",
    "from cctv_optmz_query import QueryCollection\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# preprocessing function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "\n",
    "# datetime\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# pickle\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split # data split\n",
    "from sklearn.preprocessing import MinMaxScaler # scaler\n",
    "from sklearn.ensemble import RandomForestRegressor # RF model\n",
    "from sklearn.metrics import r2_score, mean_squared_error # model evaluation\n",
    "\n",
    "# annotation\n",
    "from typing import Tuple, Type\n",
    "\n",
    "# pyspark processing function\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# import, export Folder\n",
    "MODEL_FOLDER = '/home/ec2-user/workspace/01.Incheon/02_cctv_optmz/model_learning/model'\n",
    "SCALER_FOLDER = '/home/ec2-user/workspace/01.Incheon/02_cctv_optmz/model_learning/scaler'\n",
    "\n",
    "MONTH_PERIOD = 2\n",
    "MONTH_PERIOD_HALF = MONTH_PERIOD // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4f1d84-e5e5-4d94-9563-36ce2bddaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:42:09: Main-Process : start\n",
      "15:42:09: -- spark load --\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# line break\n",
    "line_break = '\\n'\n",
    "\n",
    "# logging setting\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n",
    "logging.info(\"Main-Process : start\")\n",
    "start = time.time()\n",
    "\n",
    "logging.info(f\"-- spark load --{line_break}\")\n",
    "\n",
    "# .py 실행 파라미터로 첫번째 인자에 실행현재(YYYYMMDD) 날짜가 들어옴\n",
    "today = str(sys.argv[1])\n",
    "today = '20230601'\n",
    "\n",
    "assert len(today) == 8, \"입력일자는 YYYYMMDD 형식 입니다\"\n",
    "\n",
    "# today를 datetime 타입으로 변환하여 저장하는 변수\n",
    "today_dt : Type[datetime] = datetime.strptime(today, '%Y%m%d')\n",
    "\n",
    "# 인천시 구 딕셔너리 (구 이름 : 구 코드)\n",
    "gu_dict = {\n",
    "    'Bupyeong-gu': 28237,\n",
    "    'Dong-gu': 28140,\n",
    "    'Jung-gu': 28110,\n",
    "    'Gyeyang-gu': 28245,\n",
    "    'Namdong-gu': 28200,\n",
    "    'Ongjin-gun': 28720,\n",
    "    'Yeonsu-gu': 28185,\n",
    "    'Michuhol-gu': 28177,\n",
    "    'Seo-gu': 28260,\n",
    "    'Ganghwa-gun': 28710\n",
    "}\n",
    "\n",
    "gu_nm = 'Bupyeong-gu'\n",
    "gu_cd = 28237\n",
    "\n",
    "# cctv_optmz_query 인스턴스 생성\n",
    "query_obj = QueryCollection(today, gu_cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49f71c6-f81a-4a46-b1e4-726dd6842689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220501 20220531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:44:26: -- create_train_df() 종료 --                                            \n"
     ]
    }
   ],
   "source": [
    "def create_train_df() -> 'pandas.DataFrame':\n",
    "    \"\"\"01. 여성 유동인구 데이터를 로딩하는 함수\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df : pandas.DataFrame\n",
    "       학습 데이터셋\n",
    "    \"\"\"\n",
    "\n",
    "    for year in range(0, 5):\n",
    "\n",
    "        # 일자 설정\n",
    "        start_date = (today_dt - relativedelta(years=year, months=MONTH_PERIOD_HALF)).strftime('%Y%m%d')\n",
    "        end_date = (today_dt - relativedelta(years=year, days=1)).strftime('%Y%m%d')\n",
    "\n",
    "        # (1개월 전 ~ 어제) 통계 데이터를 불러오는 코드\n",
    "        train_df = query_obj.get_train_women_pop_sql(start_date, end_date)\n",
    "\n",
    "        if train_df.take(1):\n",
    "            print(start_date, end_date)\n",
    "            break\n",
    "\n",
    "    # 요일 변수 생성\n",
    "    train_df = train_df.withColumn('weekday', F.to_date(F.unix_timestamp('stdr_de', 'yyyyMMdd').cast(\"timestamp\")))\n",
    "    train_df = train_df.withColumn('weekday', F.date_format('weekday', 'E'))\n",
    "\n",
    "    # 학습용 여성 유동인구 수 데이터 로딩 함수 실행\n",
    "    train_df = train_df.toPandas()\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 01. 훈련 데이터 가져오기\n",
    "train_df = create_train_df()\n",
    "logging.info('-- create_train_df() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b0fc6-e3f7-4f1c-9810-3e1e4726c462",
   "metadata": {},
   "source": [
    "# merge_statistic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a784cb62-4751-47bf-82a8-8e738def8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_statistic_df(train_df: 'pandas.DataFrame') -> 'pandas.DataFrame':\n",
    "    \"\"\"02. 통계용 여성 유동인구 데이터 셋을 결합하는 함수\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df : pandas.DataFrame\n",
    "       학습 데이터\n",
    "    \"\"\"\n",
    "\n",
    "    for year in range(0, 5):\n",
    "        # 일자 설정\n",
    "        start_date = (today_dt - relativedelta(years=year, months=MONTH_PERIOD)).strftime('%Y%m%d')\n",
    "        end_date = (today_dt - relativedelta(years=year, months=MONTH_PERIOD_HALF, days=1)).strftime('%Y%m%d')\n",
    "\n",
    "        # (2개월 전 ~ 1개월 1일 전) 통계 데이터를 불러오는 코드\n",
    "        statistic_df = query_obj.get_statistic_women_pop_sql(start_date, end_date)\n",
    "\n",
    "        if statistic_df.take(1):\n",
    "            print(start_date, end_date)\n",
    "            break\n",
    "\n",
    "    # 통계용 데이터 요일 컬럼 생성\n",
    "    statistic_df = statistic_df.withColumn('weekday', F.to_date(F.unix_timestamp('stdr_de', 'yyyyMMdd').cast(\"timestamp\")))\n",
    "    statistic_df = statistic_df.withColumn('weekday', F.date_format('weekday', 'E'))\n",
    "\n",
    "    # 그리드별-시간별-요일별 여성유동인구 평균, 그리드별-시간별-요일별 여성유동인구 최댓값\n",
    "    statistic_df = statistic_df.groupby(['grid_id', 'stdr_tm', 'weekday']).agg( F.mean('women_pop').alias('women_pop_mean'), F.max('women_pop').alias('women_pop_max'))\n",
    "    statistic_df = statistic_df.toPandas()\n",
    "\n",
    "    # 통계용 데이터와 학습용 데이터 inner join\n",
    "    train_df = train_df.merge(statistic_df, how='inner', on=['grid_id', 'stdr_tm', 'weekday'])\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864bae5c-4e7c-456b-a3eb-12fc068c8b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220401 20220430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:45:56: -- merge_statistic_df() 종료 --                                         \n"
     ]
    }
   ],
   "source": [
    "# 02. 통계 데이터 결합하기\n",
    "train_df = merge_statistic_df(train_df)\n",
    "logging.info('-- merge_statistic_df() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe763bf-b961-4494-ae73-4adaf1f47f7a",
   "metadata": {},
   "source": [
    "# merge_bus_stop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d6b5a1-143b-4cbb-b407-db5ca712b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bus_stop_df(train_df: 'pandas.DataFrame') -> 'pandas.DataFrame':\n",
    "    \"\"\"03. 버스정류소 개수 데이터 셋을 결합하는 함수\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df : pandas.DataFrame\n",
    "       학습 데이터\n",
    "    \"\"\"\n",
    "\n",
    "    # 버스정류소 개수 데이터 로딩\n",
    "    bus_stop_cnt_df = query_obj.get_bus_stop_cnt_sql()\n",
    "    \n",
    "    if not bus_stop_cnt_df.take(1):\n",
    "        logging.error('bus_stop_cnt_df no data')\n",
    "    \n",
    "    bus_stop_cnt_df = bus_stop_cnt_df.toPandas()\n",
    "\n",
    "    train_df = train_df.merge(bus_stop_cnt_df, how='left', on='grid_id')\n",
    "    train_df['bus_stop_cnt'].fillna(0, inplace=True)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b425704a-d853-4dc0-802a-42aa0c1a367b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:48:34: -- merge_bus_stop_df() 종료 --                                          \n"
     ]
    }
   ],
   "source": [
    "# 03. 버스정류소 개수 데이터 결합하기\n",
    "train_df = merge_bus_stop_df(train_df)\n",
    "logging.info('-- merge_bus_stop_df() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd54288-9bb0-4696-a0ad-0e7d295bd8b7",
   "metadata": {},
   "source": [
    "# apply_get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c786efb-a157-4e41-9280-7d589b2b6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_get_dummies(train_df: 'pandas.DataFrame'):\n",
    "    \n",
    "    # 범주형 변수(요일) One-Hot Encoding\n",
    "    train_df = pd.get_dummies(train_df, columns=['weekday'])\n",
    "\n",
    "    # 없는 요일 범주형 변수 만들기\n",
    "    days = [ 'weekday_Mon', 'weekday_Tue', 'weekday_Wed', 'weekday_Thu', 'weekday_Fri', 'weekday_Sat', 'weekday_Sun' ]\n",
    "\n",
    "    for day in filter(lambda x: x not in train_df.columns, days):\n",
    "        train_df[day] = np.uint8(0)\n",
    "        \n",
    "    cols = [\n",
    "        'stdr_de',\n",
    "        'stdr_tm',\n",
    "        'grid_id',\n",
    "        'women_pop',\n",
    "        'women_pop_mean',\n",
    "        'women_pop_max',\n",
    "        'bus_stop_cnt'\n",
    "    ]\n",
    "    \n",
    "    cols.extend(days)\n",
    "    \n",
    "    train_df = train_df.reindex(columns=cols)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "train_df = apply_get_dummies(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d65cf-c020-400c-8a81-37ce218ec000",
   "metadata": {},
   "source": [
    "# split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa2a45f-52e8-42ae-95a5-591a18694545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weekday_Mon', 'weekday_Tue', 'weekday_Wed', 'weekday_Thu',\n",
       "       'weekday_Fri', 'weekday_Sat', 'weekday_Sun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fccdf631-16a4-4248-a66e-16fee7bc7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:05:51: -- split_train_test() 종료 --\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(dataFrame: 'pandas.DataFrame')-> Tuple['pandas.DataFrame', 'pandas.DataFrame', 'pandas.DataFrame', 'pandas.DataFrame']:\n",
    "    \"\"\"04. 학습용 데이터, 테스트용 데이터를 분리하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataFrame : pandas.DataFrame\n",
    "       학습 데이터\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_x : pandas.DataFrame\n",
    "       모델 학습 독립변수 데이터 \n",
    "\n",
    "    test_x : pandas.DataFrame\n",
    "       모델 학습 종속변수 데이터 \n",
    "\n",
    "    train_y : pandas.DataFrame\n",
    "       모델 테스트 독립변수 데이터 \n",
    "\n",
    "    test_y : pandas.DataFrame\n",
    "       모델 테스트 종속변수 데이터 \n",
    "    \"\"\"\n",
    "\n",
    "    # 학습 데이터, 테스트 데이터 분리하기\n",
    "    x = dataFrame[['women_pop_mean', 'women_pop_max', 'bus_stop_cnt',\n",
    "                   'weekday_Mon', 'weekday_Tue', 'weekday_Wed', 'weekday_Thu', 'weekday_Fri', 'weekday_Sat', 'weekday_Sun']]\n",
    "    \n",
    "    y = dataFrame[['women_pop']]\n",
    "\n",
    "    # 데이터 분리하기 \n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "# 04. 모델 분리하기\n",
    "train_x, test_x, train_y, test_y = split_train_test(train_df)\n",
    "logging.info('-- split_train_test() 종료 --')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f778215-0c02-42e5-a91e-dca2ba55691c",
   "metadata": {},
   "source": [
    "# store_min_max_sacler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "433b9a58-e81c-4bde-8252-dd2f231ed790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_min_max_sacler(train_x: 'pandas.DataFrame'):\n",
    "    \n",
    "    # MinMaxScaler 불러오기\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "\n",
    "    # 연속형 변수 MinMaxScaler Fit & Transform\n",
    "    train_x[['women_pop_mean', 'women_pop_max', 'bus_stop_cnt']] =  min_max_scaler.fit_transform(train_x[['women_pop_mean', 'women_pop_max', 'bus_stop_cnt']])\n",
    "\n",
    "    # Save MinMaxScaler\n",
    "    joblib.dump(min_max_scaler, os.path.join(SCALER_FOLDER, f'{gu_nm}_scaler.pkl'))\n",
    "    \n",
    "    return train_x\n",
    "\n",
    "train_x = store_min_max_sacler(train_x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4df559-251c-4590-a1ad-988913f5bb2b",
   "metadata": {},
   "source": [
    "# train_women_pop_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a57efc9b-0f87-4a37-846f-b38106b86ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:28: RandomForestRegressor Bupyeong-gu 학습시작 --\n"
     ]
    }
   ],
   "source": [
    "def train_women_pop_model(train_x: 'pandas.DataFrame', train_y: 'pandas.DataFrame'):\n",
    "    \"\"\"05. 학습용 데이터를 학습시키는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_x : pandas.DataFrame\n",
    "       모델 학습 독립변수 데이터 \n",
    "\n",
    "    train_y : pandas.DataFrame\n",
    "       모델 테스트 독립변수 데이터      \n",
    "    \"\"\"\n",
    "\n",
    "    # 모델 생성 및 학습\n",
    "    logging.info(f'RandomForestRegressor {gu_nm} 학습시작 --')\n",
    "    rf = RandomForestRegressor(max_depth=6)\n",
    "    rf.fit(train_x, train_y)\n",
    "\n",
    "    # Save RandomForest Regreesion Model\n",
    "    joblib.dump(rf, os.path.join(MODEL_FOLDER, f'{gu_nm}_rf.pkl'))\n",
    "    \n",
    "train_women_pop_model(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734a6f4-22fd-436f-8754-c6f675739d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_women_pop(test_x: 'pandas.DataFrame', test_y: 'pandas.DataFrame'):\n",
    "    \"\"\"05. 테스트 데이터를 평가하는 함수\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataFrame : pandas.DataFrame\n",
    "       학습 데이터\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_x : pandas.DataFrame\n",
    "       모델 학습 종속변수 데이터 \n",
    "\n",
    "    test_y : pandas.DataFrame\n",
    "       모델 테스트 종속변수 데이터 \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load MinMaxScaler\n",
    "    min_max_scaler = joblib.load(os.path.join(SCALER_FOLDER, f'{gu_nm}_scaler.pkl'))\n",
    "\n",
    "    # 연속형 변수 MinMaxScaler Transform\n",
    "    test_x[['women_pop_mean', 'women_pop_max', 'bus_stop_cnt']] =  min_max_scaler.transform(test_x[['women_pop_mean', 'women_pop_max', 'bus_stop_cnt']])\n",
    "\n",
    "    # Load RandomForest Regression Model\n",
    "    rf = joblib.load(os.path.join(MODEL_FOLDER, f'{gu_nm}_rf.pkl'))\n",
    "\n",
    "    # 모델 예측\n",
    "    test_pred = rf.predict(test_x)\n",
    "\n",
    "    # 평가 지표\n",
    "    r2 = r2_score(test_y, test_pred)\n",
    "    logging.info(f'R2-SCORE : {round(r2, 2)}')\n",
    "    \n",
    "    mse = mean_squared_error(test_y, test_pred)\n",
    "    logging.info(f'MSE : {round(mse, 2)}')\n",
    "\n",
    "    rmse = mean_squared_error(test_y, test_pred, squared=False)\n",
    "    logging.info(f'RMSE : {round(rmse, 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c7230-8485-453a-bc83-4e8cb2b9ef89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d28f44-3f05-407b-9079-3acb63dbd217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed684d78-bf38-400a-9935-ddc103fe9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 상관계수\n",
    "2. 산포도를 그린다 (scatter plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae540d4-1ad0-4fe1-9a44-904506c4b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f923b9-0487-440e-bdb9-206d80acc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train_df[train_df.columns[3:7]].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7463f4-e284-4803-ba14-976d5f04e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef86804-66b7-41bd-ad70-c247a2a7c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_x['weekday'], columns=['weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee310b-6c30-49d3-9cd9-619be5a4a0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d319d7b-636c-4451-b69f-988498910a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a923d-99ed-4841-be81-ad2691d0843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b4cc1-a126-4d8b-806e-9225e4301b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1721f-4b68-41c6-b9f0-76a7d2b626d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train_x['weekday']).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75faf2d-8370-4623-98fc-49494fbdad0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f76ba-ac28-4c09-a119-9d37ae8c6172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853bdd0-e69c-455c-b893-10d79ca1573a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8943b-76b7-4b0f-aa71-9c8b23844d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
